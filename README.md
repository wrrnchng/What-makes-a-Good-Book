# üìö Book Popularity Classification

![Python](https://img.shields.io/badge/Python-3.8-blue)
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-0.24-orange)
![License: MIT](https://img.shields.io/badge/License-MIT-green)
![GitHub stars](https://img.shields.io/github/stars/wrrnchng/What-makes-a-Good-Book)
![GitHub forks](https://img.shields.io/github/forks/wrrnchng/What-makes-a-Good-Book)

### Disclaimer
*This project is based on files and datasets provided by DataCamp as part of their real-world projects. The dataset and structure align with educational content from DataCamp to help learners practice machine learning techniques in real-world scenarios.*

This project builds a binary classification model to determine whether a book is "Popular" or "Unpopular" based on price, review helpfulness, authors, and categories.

### üöÄ Features

  - Machine Learning Model: Uses Random Forest Classifier with hyperparameter tuning.

  - Natural Language Processing (NLP): Utilizes TF-IDF to process text data.

  - Feature Engineering: Converts categorical and text data into numerical form.

  - Hyperparameter Optimization: Uses GridSearchCV for the best model.
    
### üõ†Ô∏è Installation & Setup

1Ô∏è‚É£ Clone the repository
    
    git clone https://github.com/YOUR_USERNAME/book-popularity-classification.git
    cd book-popularity-classification

2Ô∏è‚É£ Install dependencies

    pip install -r requirements.txt

3Ô∏è‚É£ Run the Model

    python book_popularity_model.py

### üìä Dataset

The dataset contains the following features:

  - price (float) ‚Äì The book's price.

  - review/helpfulness (float) ‚Äì Fraction representing helpfulness votes (converted to float).

  - review/summary, review/text (text) ‚Äì Book reviews.

  - authors, categories (categorical) ‚Äì Encoded using one-hot encoding.

### ü§ñ Model Training

1. Preprocessing

    - Converts categorical and text data into numerical values.

    - Uses TF-IDF for text feature extraction.

    - Scales numerical data.

2. Hyperparameter Tuning

    - Uses GridSearchCV to find the best parameters for RandomForestClassifier.

3. Evaluation

    - Uses Accuracy Score and classification_report to measure performance.

### üìà Results

  - Best accuracy score: Stored in model_accuracy variable.

  - Model performance is printed in the console.

### ü§ù Contributing

Feel free to fork this repository and submit pull requests.

### üìú License

This project is licensed under the MIT License.

